{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c0b028b-d1bd-4669-87c9-bf611ce12dac",
   "metadata": {},
   "source": [
    "# Damiano Bressanin 138075\n",
    "\n",
    "\n",
    "Ho preso spunto da:\n",
    "- \"Very Deep Convolutional Networks for Large-Scale Image Recognition\" https://arxiv.org/pdf/1409.1556.pdf\n",
    "- \"How to Classify Photos of Dogs and Cats\" di Jason Brownlee. https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/\n",
    "- https://keras.io/guides/transfer_learning/\n",
    "- https://keras.io/api/applications/vgg/#vgg16-function\n",
    "\n",
    "\n",
    "\n",
    "# Test:\n",
    "- Dataset 80-10-10;\n",
    "- Foto a colori;\n",
    "- Sì Data Augmentation;\n",
    "- Transfer Learning e Fine Tuning con VGG16;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795f8fdc-13b7-4566-b545-50f32e332c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 18:15:21.718623: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.image import imread\n",
    "from matplotlib import pyplot\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41738da-e0e2-4f7f-9584-6b9cc463361b",
   "metadata": {},
   "source": [
    "# Preprocessing e Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4bc5752-ff85-4f57-a943-2130d91bbc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19997 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# vedi paper\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    shear_range=0.2,\n",
    "#    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    brightness_range=[0.8,1.2],\n",
    "#    rotation_range=20,\n",
    "#    width_shift_range=0.15,\n",
    "#    height_shift_range=0.15,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_datagen.mean = [123.68, 116.779, 103.939]\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(featurewise_center=True)\n",
    "test_datagen.mean = [123.68, 116.779, 103.939]\n",
    "\n",
    "val_datagen = ImageDataGenerator(featurewise_center=True)\n",
    "val_datagen.mean = [123.68, 116.779, 103.939]\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_it = train_datagen.flow_from_directory(\"dataset_diviso_v2/train/\",\n",
    "                                             class_mode='binary',\n",
    "                                             batch_size=batch_size,\n",
    "                                             target_size=(224, 224),\n",
    "                                             color_mode=\"rgb\",\n",
    "                                             shuffle=True,\n",
    "                                             seed=42\n",
    "                                            )\n",
    "\n",
    "val_it = val_datagen.flow_from_directory('dataset_diviso_v2/valid/',\n",
    "                                         class_mode='binary',\n",
    "                                         batch_size=batch_size,\n",
    "                                         target_size=(224, 224),\n",
    "                                         color_mode=\"rgb\",\n",
    "                                         shuffle=True,\n",
    "                                         seed=42)\n",
    "\n",
    "test_it = test_datagen.flow_from_directory('dataset_diviso_v2/test/',\n",
    "                                           class_mode='binary',\n",
    "                                           batch_size=batch_size,\n",
    "                                           target_size=(224, 224),\n",
    "                                           color_mode=\"rgb\",\n",
    "                                           shuffle=True,\n",
    "                                           seed=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5c198-4f94-4ee8-9e95-b13c3f6da5e9",
   "metadata": {},
   "source": [
    "# Creazione del modello:\n",
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e428a012-2c2e-4909-b882-5e3a2fcce7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "def define_model():\n",
    "    # carico il modello\n",
    "    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "    # congelo gli strati\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    # aggiungo parte finale\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(256, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    class2 = Dense(256, activation='relu', kernel_initializer='he_uniform') (class1)\n",
    "    output = Dense(1, activation='sigmoid')(class2)\n",
    "    \n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    \n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ff7bba-ec37-46ce-9351-fd2a3698ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa9d95c-2fd8-415c-9f18-551d04fc474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "unique_name = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/fit/\" + unique_name\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, update_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f57028f-9a7d-42f7-b7ab-3fdd542315b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 18:15:26.389798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-27 18:15:26.396457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-27 18:15:26.396838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-27 18:15:26.398457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-27 18:15:26.398970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-27 18:15:26.399418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-27 18:15:27.231563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-27 18:15:27.232490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-27 18:15:27.232523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-27 18:15:27.233054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-27 18:15:27.233096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6582 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 18:15:30.517369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-08-27 18:15:35.949774: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1bb7c830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-27 18:15:35.949839: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1070, Compute Capability 6.1\n",
      "2023-08-27 18:15:36.019037: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/625 [================>.............] - ETA: 1:44 - loss: 0.4380 - accuracy: 0.9514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/PIL/TiffImagePlugin.py:866: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 277s 432ms/step - loss: 0.2940 - accuracy: 0.9603 - val_loss: 0.0700 - val_accuracy: 0.9728\n",
      "Epoch 2/30\n",
      "625/625 [==============================] - 264s 421ms/step - loss: 0.0525 - accuracy: 0.9819 - val_loss: 0.0622 - val_accuracy: 0.9764\n",
      "Epoch 3/30\n",
      "625/625 [==============================] - 262s 418ms/step - loss: 0.0289 - accuracy: 0.9893 - val_loss: 0.0602 - val_accuracy: 0.9784\n",
      "Epoch 4/30\n",
      "625/625 [==============================] - 264s 421ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.0732 - val_accuracy: 0.9804\n",
      "Epoch 5/30\n",
      "625/625 [==============================] - 262s 419ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.0748 - val_accuracy: 0.9808\n",
      "Epoch 6/30\n",
      "625/625 [==============================] - 262s 420ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0817 - val_accuracy: 0.9792\n",
      "Epoch 7/30\n",
      "625/625 [==============================] - 262s 419ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0875 - val_accuracy: 0.9828\n",
      "Epoch 8/30\n",
      "625/625 [==============================] - 267s 426ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0935 - val_accuracy: 0.9832\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model=define_model()\n",
    "\n",
    "history = model.fit(train_it, steps_per_epoch=len(train_it), validation_data=val_it, validation_steps=len(val_it), epochs=30, verbose=1, callbacks=[tensorboard_callback,early_stop],validation_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cb91b7-8807-467a-aa44-06bddc7815e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 11s 134ms/step - loss: 0.0511 - accuracy: 0.9828\n",
      "> 98.280\n"
     ]
    }
   ],
   "source": [
    "# valuto il modello\n",
    "_, acc = model.evaluate(test_it, steps=len(test_it), verbose=1)\n",
    "print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aa234d-eb1c-4ec1-973f-04dbd895a2c1",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92f295d8-02db-493d-ae52-c9fa9706a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# learning rate più basso\n",
    "opt=SGD(learning_rate=0.00005, momentum=0.9)\n",
    "\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7cf91f1-d58b-4912-9322-d092e098467b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "625/625 [==============================] - 301s 465ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0555 - val_accuracy: 0.9792\n",
      "Epoch 2/30\n",
      "625/625 [==============================] - 306s 488ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.0578 - val_accuracy: 0.9824\n",
      "Epoch 3/30\n",
      "625/625 [==============================] - 293s 469ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0547 - val_accuracy: 0.9824\n",
      "Epoch 4/30\n",
      "625/625 [==============================] - 311s 497ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
      "Epoch 5/30\n",
      "625/625 [==============================] - 295s 471ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0582 - val_accuracy: 0.9836\n",
      "Epoch 6/30\n",
      "625/625 [==============================] - 299s 477ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0591 - val_accuracy: 0.9840\n",
      "Epoch 7/30\n",
      "625/625 [==============================] - 315s 504ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0619 - val_accuracy: 0.9836\n",
      "Epoch 8/30\n",
      "625/625 [==============================] - 295s 471ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0627 - val_accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "train_it.reset\n",
    "val_it.reset\n",
    "test_it.reset\n",
    "\n",
    "\n",
    "history = model.fit(train_it, steps_per_epoch=len(train_it), validation_data=val_it, validation_steps=len(val_it), epochs=30, verbose=1, callbacks=[tensorboard_callback,early_stop],validation_split=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42c4d6fb-3f4c-4b34-b983-f984230403dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 11s 134ms/step - loss: 0.0439 - accuracy: 0.9880\n",
      "> 98.800\n"
     ]
    }
   ],
   "source": [
    "# valuto il modello\n",
    "_, acc = model.evaluate(test_it, steps=len(test_it), verbose=1)\n",
    "print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345d90a8-1059-4eb8-b52e-3595cb48136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6422784   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21203521 (80.89 MB)\n",
      "Trainable params: 21203521 (80.89 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba6f086-4a8d-4ad8-979d-a67f8684c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"modelli/\"+ unique_name +\".keras\"\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e22c4322-f6a1-4eb5-98a3-14fefc41b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    pyplot.figure(figsize=(20, 15))\n",
    "    \n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='orange', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='blue', label='val')\n",
    "    pyplot.legend(loc='upper right') # legenda\n",
    "    pyplot.grid(which='both', linestyle='-', linewidth=1, color='black')  # griglia nera\n",
    "    \n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='red', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='green', label='val')\n",
    "    pyplot.legend(loc='lower right')\n",
    "    pyplot.grid(which='both', linestyle='-', linewidth=1, color='black')\n",
    "\n",
    "    # salvo i plot su file\n",
    "    filename = 'plot/' + unique_name\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()\n",
    "    \n",
    "summarize_diagnostics(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
